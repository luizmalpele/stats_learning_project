---
title: "R Notebook"
output:
  pdf_document:
    toc: yes
  html_document:
    theme: united
    toc: yes
    toc_float: yes
---

```{r}
library(tidyverse)
library(caret)
library(DataExplorer)
library(fastDummies)
library(leaps)
library(cowplot)
library(GGally)
```
### Dataset
Import processed data, which can be found [here] ("https://github.com/luizmalpele/stats_learning_project/blob/master/data/data.Rmd")

```{r}
#read preprocessed data
college_data <- read.csv(file = '../data/college_data.csv')
```

View data info
```{r}
glimpse(college_data)
```

Use DataExplorer to automatically create an EDA
```{r}
#create_report(college_data)
```

EDA etc

```{r}
#overlay early pay distribution with middle play distribution
college_data %>% 
  ggplot() +
  geom_histogram(mapping = aes(x = early_career_pay), 
                 fill = "red",
                 alpha = 0.6) +
  geom_histogram(mapping = aes(x = mid_career_pay), 
                 fill = "blue",
                 alpha = 0.6) +
  xlab("Pay") +
  ylab("Count") +
  theme_minimal()
```

What types of colleges want to make the world better?
  (maybe subset grep(Art, creative) and grep(health, nursing) and compare boxplots of 'make_world_better_percent')
```{r}
college_data %>% 
  filter(!is.na(make_world_better_percent)) %>% 
  select(name, make_world_better_percent) %>% 
  arrange(make_world_better_percent)
```


Useful for EDA:
-make a correlation matrix

Questions these models hope to answer
-Does the aspiration of making the world better have an impact on the mid career payment?
  -How does it affect the early stage of a students career?
  -Does it apply to only some specific fields?

-Are more diverse schools likely to have a higher % of alumni who want to change the world?

-Do lower tuition and fees cause people to want to care more about the world?

Translate these questions into statistical models:
What variables most impacts mid level pay? (LASSO or PCA + linear regression)




```{r}
college_dataset <-  college_data %>% 
  dummy_cols(select_columns = "degree_length") %>% 
  dummy_cols(select_columns = "type") %>% 
  rename(length_2y="degree_length_2 Year", 
         length_4y="degree_length_4 Year", 
         for_profit="type_For Profit", 
         private="type_Private", 
         public = "type_Public") %>% 
  select(-degree_length_Other, -type_Other) %>%  
  filter(!is.na(make_world_better_percent)) %>% 
  filter(!is.na(total_enrollment)) %>% 
  mutate(women_ratio=round(women/total_enrollment*100, 2),
         native_american_ratio=round(native_american/total_enrollment*100, 2),
         asian_ratio=round(asian/total_enrollment*100, 2),
         black_ratio=round(black/total_enrollment*100, 2),
         hispanic_ratio=round(hispanic/total_enrollment*100, 2),
         pacific_islander_ratio=round(pacific_islander/total_enrollment*100, 2),
         white_ratio=round(white/total_enrollment*100, 2),
         minority_ratio=round(total_minority/total_enrollment*100, 2)) %>% 
  mutate(ln_early_career_pay=log(early_career_pay),
         ln_mid_career_pay=log(mid_career_pay),
         ln_in_state_tuition=log(in_state_tuition),
         ln_in_state_total=log(in_state_total),
         ln_out_of_state_tuition=log(out_of_state_tuition),
         ln_out_of_state_total=log(out_of_state_total),
         ln_room_and_board=log(room_and_board),
         tuition_ratio=out_of_state_tuition/in_state_tuition,
         tuition_total_ratio=out_of_state_total/in_state_total)
college_dataset <- na.omit(college_dataset)
college_dataset
```

```{r}
college_dataset_analysis <- college_dataset %>%
  select(-state, -type, -degree_length, -early_career_pay, -mid_career_pay, ln_mid_career_pay)
college_dataset_analysis
```


- Colleges for Profit did not collected data on "Make World Better".

```{r}
#create_report(college_dataset)
```

```{r}
college_dataset %>% 
  ggplot() +
  geom_histogram(mapping = aes(x = early_career_pay), 
                 fill = "red",
                 alpha = 0.6) +
  geom_histogram(mapping = aes(x = mid_career_pay), 
                 fill = "blue",
                 alpha = 0.6) +
  xlab("Pay") +
  ylab("Count") +
  theme_minimal()
```


```{r}
college_dataset_shrinked <- college_dataset %>% 
  select(ln_early_career_pay,
         asian_ratio,  
         ln_out_of_state_tuition,
         stem_percent, 
         ln_room_and_board,
         private,
         black_ratio,
         rank,
         women_ratio)

college_dataset_shrinked2 <- college_dataset %>% 
    select(ln_early_career_pay,
         asian_ratio,  
         ln_out_of_state_tuition,
         stem_percent, 
         ln_room_and_board,
         private,
         black_ratio,
         rank,
         women_ratio)
```

```{r}
ggpairs(data = college_dataset_shrinked, lower = list(continuous = wrap("smooth", alpha = 0.3, size=0.1)))
```

```{r}
ggpairs(data = college_dataset_shrinked2, lower = list(continuous = wrap("smooth", alpha = 0.3, size=0.1)))
```

```{r}
college_dataset %>% 
  ggplot() + 
  geom_point(aes(x=ln_out_of_state_total, y=make_world_better_percent, color = type), alpha = 0.6) + 
  labs(
    title = "Log of Out of State Total versus Percentage of Students seeking a Better World ", 
    x = "Log of Out of State Total", 
    y = "Percentage Students seeking a Better World", 
    color = "Type of Institution") + scale_color_brewer(palette = "Set1")
```

```{r}
college_dataset %>% 
  ggplot() + 
  geom_point(aes(x=ln_out_of_state_total, y=ln_early_career_pay, color = type), alpha = 0.6) + 
  labs(
    title = "Log of Out of State Total versus Percentage of Students seeking a Better World ", 
    x = "Log of Out of State Total", 
    y = "Percentage Students seeking a Better World", 
    color = "Type of Institution") + scale_color_brewer(palette = "Set1")
```

Separating the data into Train and Test

```{r}
set.seed(123)
train_control <-  trainControl(method = "cv", number = 10)
inTrain <- createDataPartition(y = college_dataset_analysis$ln_early_career_pay, p = 0.8, list = FALSE)
train_set <- college_dataset_analysis[inTrain , ]
test_set <- college_dataset_analysis[-inTrain , ]
```

  This command separates 80% of the data into a training set, and other 20% into a testing set. This is done to avoid overfitting and it is preferable to perform the final model selection with an out of sample criterion.

__Variables selection__

```{r}
#Separating the data
sub_fit_pay <- regsubsets(ln_early_career_pay ~  
                            asian_ratio + 
                            ln_out_of_state_tuition + 
                            stem_percent + 
                            ln_room_and_board + 
                            private +
                            black_ratio + 
                            rank + 
                            women_ratio, 
                          data = train_set)

best_summary <- summary(sub_fit_pay)

#Plots
par(mfrow = c(1,2)) 
plot(best_summary$cp, xlab = "Number of features", ylab = "Mallows Cp", main = "Optimal Number of Predictors: Cp", col = "dark blue", type = "b")

plot(sub_fit_pay, scale = "Cp", main = "Best Variables for Modelling", col = "dark red")
par(mfrow = c(1,2))

plot(best_summary$adjr2, xlab = "Number of features", ylab = "Adjusted-R^2", main = "Optimal Number of Predictors", col = "dark blue", type = "b")

plot(best_summary$bic, xlab = "Number of features", ylab = "BIC", main = "Optimal Number of Predictors", col = "dark red", type = "b")
```

 Based on BIC, Mallows' CP, and the $Adjusted-R^2$, the select model will account for 6 predictors, more than this will result in overfitting and these variables will be: __stem_percent, room_and_board, ln_out_of_state_tuition, rank, women_ratio, black_ratio, and asian_ratio__. 
 
# Modeling With other Techniques
```{r}
set.seed(123)
train_control <-  trainControl(method = "cv", number = 10)
inTrain <- createDataPartition(y = college_dataset_shrinked2$ln_early_career_pay, p = 0.8, list = FALSE)
iz_train_set <- college_dataset_shrinked2[inTrain ,]
iz_test_set <- college_dataset_shrinked2[-inTrain ,]

```

## PCA
This gives an R^2 value of 0.96 but NO IDEA HOW
```{r}
glm_pca_model <- train(ln_early_career_pay ~ . , 
                 data = iz_train_set, 
                 method = "glm", 
                 preProcess = "pca", 
                 trControl = train_control)
glm_pca_model
```



## Simple Linear Regression
 
```{r}
earlypay_lm <- lm(ln_early_career_pay ~  asian_ratio + 
                    ln_out_of_state_tuition + 
                    stem_percent + 
                    ln_room_and_board + 
                    black_ratio + 
                    rank + 
                    women_ratio, 
                  data = train_set)
summary(earlypay_lm)
```

## Random Forest
We chose this because
```{r}
oob <- trainControl(method = "oob")
cv_5 <- trainControl(method = "cv", number = 5)
rf_grid <- expand.grid(mtry = 1:10)

set.seed(825)
rf_model <- train(ln_early_career_pay ~ ., data = iz_train_set,
                     method = "rf",
                     trControl = oob,
                     verbose = FALSE,
                     tuneGrid = rf_grid)
# print results
rf_model
```

```{r}
calc_acc <- function(actual, predicted) {
  mean(actual == predicted)
}
```

## SVM
Preprocessing
```{r}
set.seed(123)
college_dataset_shrinked <- na.omit(college_dataset_shrinked)

#Creating trainging and testing data
inTrain <- createDataPartition(y = college_dataset_shrinked$ln_early_career_pay , p = 0.8, list = FALSE)

train_data <- college_dataset_shrinked[inTrain,]
test_data <- college_dataset_shrinked[-inTrain,]

#train control 
tr_control <- trainControl(method = "cv", number = 10)

# grid
tGrid <- expand.grid(C = c(0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2, 5))
```

Model
```{r}
# model 1:
svm_model_1 <- train(ln_early_career_pay ~ .,
  data = train_data, 
  method = "svmLinear",
  tuneGrid = tGrid, 
  trControl = tr_control, 
  metric = "RMSE",
  preProcess = c("center", "scale")
)
svm_model_1
```


